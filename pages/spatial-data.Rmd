---
title: "Spatial Data"
output: 
  html_document:
    toc: true
    toc_float: true
editor_options: 
  markdown: 
    wrap: sentence
code-block-border-left: true
---

```{r setup, include=FALSE}
knitr::opts_knit$set(root.dir = normalizePath('../'))
knitr::opts_chunk$set(echo = TRUE, fig.align = 'center', warning = FALSE, message = FALSE)
```
```{r, include=FALSE}
source("./utils/load_libraries.R")
```
## Objectives ðŸŽ¯
- _Get an introduction to the type of data we are going to use_
- _Load the data into a `Seurat` object_

# An introduction to spatial profiling technologies

Follow along on the slides for a brief intro on the kind of data we'll be using throughout the hands-on session!

# Data Loading and Exploratory Analyses

## What data are we going to use? What is our question?
As seen during the presentation, we will load data originally collected in [this study](https://www.nature.com/articles/s41467-024-47271-y) on High Grade Serous Ovarian Carcinoma (HGSOC). The original data supporting the findings of the study has been deposited on the **Gene Expression Omnibus** (GEO) data portal under accession number [GSE211956](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE211956).

The data (like all data from Visium experiments) is built in the following way and stored in the `data` folder:

- `barcodes.tsv`: the single-cell barcodes from the 10X GEMs
- `features.tsv`: the set of genes profiled during the experiment (in the case of RNA-seq)
- `matrix.mtx`: the actual cell-by-gene matrix with the count information

## Loading The Data with `Seurat`
Once we know what to expect from the data, let's load it! We are going to use functions from the `Seurat` package to load our tabular and image data into `R` so we can start working with it.

```{r}
# Load the data using Seurat (first set the proper data directory path)
datadir <- './data'

count_matrix <- Read10X(datadir,
              gene.column = 2,
              cell.column = 1,
              unique.features = TRUE,
              strip.suffix = FALSE)

# Turn matrix into SeuratObject
sp <- CreateSeuratObject(counts = count_matrix,
                        project = 'visium-hgsoc',
                        assay='Visium10X')              
```

> ðŸ¤” How many spots and genes are present in our counts table? _hint_: think of the type of experiment and the readout we are expecting!

Let's take a look at the counts matrix up close:

```{r}
# Lets examine a few genes in the first thirty cells
sp[['Visium10X']]$counts[c("CD3D", "TCL1A", "MS4A1"), 1:30]
```

The `.` values in the matrix represent 0s (no molecules detected). Since most values in an scRNA-seq matrix are 0, Seurat uses a **sparse-matrix representation** whenever possible. This results in significant memory and speed savings for Drop-seq/inDrop/10X data.

Now that we have created it, our `sp` object acts as a container for all the information we need during the analysis, more specifically, the `SeuratObject` class is composed in the following way:

<center>

<img src="../src/sce.png" width=800 />

</center>

We can see its structure also by printing it directly on screen:

```{r}
# Lets see what the object looks like
sp
```

We can also access our transcript information in the object by using the `[[` operator.

```{r}
# Lets see what the object looks like (we use the assay name given previously)
sp[['Visium10X']]
```

Now go ahead and check the cell metadata!

```{r}
#| code-fold: true
head(sp@meta.data, 5)
```

> ðŸ’¡ See how Seurat has automatically created metadata fields related to number of genes and UMIs per spot?

## Adding image data
Metadata refers to that _class of accessory data_ to the main experimental readout. In the case of this published dataset, the _main_ data refers to the actual gene expression table with the associated counts measurement for each sample. Each sample then has associated information used to further describe it (e.g. type of cells, patient ID, treatment status, experimental batch...), as we have previously seen, this information is instrumental to bioinformaticians to avoid pitfalls in the analysis.
In the case of our spatial data, we also have **associated H&E images** that we can use to overlay to actual mRNA information to aid interpretability of the results.
Since we do not need it for any quantitative analysis, we are fine with loading a low-res image in `.png` format.

```{r}
# Let's load the image
img <- Read10X_Image(image.dir = "./data/spatial/"
                     , image.name = "tissue_lowres_image.png"
                     , assay = '10Xspatial'
                     , slice = 'slice1'
                     , filter.matrix = TRUE # This is used to retain only spots "on tissue"
                     )
img
```

Now that we have loaded the image, we can put it inside our container object:

```{r}
# Assign image
sp[['image']] <- img
```

# Compute custom quality metrics
You will now compute a st of quality metrics that we will later visualize and use to filter the data to only keep high-quality cells!

**Q1.** Compute the percentage of reads that map to the mitochondrial genome, useful to detect stressed/dying cells (_hint_: use the `PercentageFeatureSet` function with the `^MT-` pattern) and store the results in a metadata field called `percent.mt`

**Q2.** Compute a measure of _transcriptional complexity_ per spot, or the total number of genes we can find per spot over the total number of spot UMIs (the two should be strongly correlated) as a ratio between the `nFeature_Visium10X` and `nCount_Visium10X` columns in the metadata and call it `transcriptome.complexity`

```{r, include=FALSE}
# Compute the amount of mitochondrial reads, this is just the total reads mapping to mitochondrial genes over the total reads in the spot
sp[["percent.mt"]] <- PercentageFeatureSet(sp, pattern = "^MT-")

# Create an additional column in the metadata
sp[['transcriptome.complexity']] <- sp@meta.data$nFeature_Visium10X / sp@meta.data$nCount_Visium10X
```

**Q3.** Plot relationships between quality metrics like shown below (_hint_: use the `FeatureScatter` function)

```{r, echo=FALSE}
# FeatureScatter is typically used to visualize feature-feature relationships, but can be used
# for anything calculated by the object, i.e. columns in object metadata, PC scores etc.
plot1 <- FeatureScatter(sp, feature1 = "nCount_Visium10X", feature2 = "percent.mt")
plot2 <- FeatureScatter(sp, feature1 = "nCount_Visium10X", feature2 = "nFeature_Visium10X")
plot1 + plot2
```

# Display sample metadata
Plot the sample with present metadata including number of features and number of counts and check their distributions!

> ðŸ’¡ Use the `SpatialFeaturePlot` function!

```{r}
#| code-fold: true
# Display the spots on the tissue
SpatialDimPlot(sp)
```

Here is our sample! We will now move towards filtering the sample and perform adequate quality control steps in the next page.

# Recap 
- Spatial technologies are many and diverse 
- Spatial data can be boiled down to either sequencing-based or imaging-based approaches
- Loaded and explored public Visium spatial data
- Built a `SeuratObject` instance that we will use in subsequent analyses

```{r, include=FALSE}
# Save Seurat object
saveRDS(sp, file = "./data/seurat_obj.rds")
```