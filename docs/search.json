[
  {
    "objectID": "pages/1-setup.html",
    "href": "pages/1-setup.html",
    "title": "Setup",
    "section": "",
    "text": "Setup RStudio\nGet familiar with the interface\nDownload relevant packages and set up the computing environment"
  },
  {
    "objectID": "pages/1-setup.html#downloading-the-workshop-contents",
    "href": "pages/1-setup.html#downloading-the-workshop-contents",
    "title": "Setup",
    "section": "Downloading the workshop contents",
    "text": "Downloading the workshop contents\nIn order to have everything ready to go through the steps of the workshop, we first need to download the required materials. To do so, click on this link. This should trigger a file download on your system.\n\nKeep track of the location of the download! We will now head into this folder using R through the Rstudio interface."
  },
  {
    "objectID": "pages/1-setup.html#initializing-rstudio",
    "href": "pages/1-setup.html#initializing-rstudio",
    "title": "Setup",
    "section": "Initializing Rstudio",
    "text": "Initializing Rstudio\nOnce RStudio is installed on your computer and opened, you should be able to see something like the following interface:\n\n\n\nThis is your working interface, the bottom right section shows your current file system. The section on the left currently displays your console, where you can type R code interactively."
  },
  {
    "objectID": "pages/1-setup.html#creating-a-new-r-project-for-the-workshop",
    "href": "pages/1-setup.html#creating-a-new-r-project-for-the-workshop",
    "title": "Setup",
    "section": "Creating a new R project for the workshop",
    "text": "Creating a new R project for the workshop\nGo ahead and create a new R project by cliking on File > New Project and name it what you want. You can think of a project as a container of everything we will use during our workshop both in terms of files as well as R objects. When you create the project, select the option to create it from an existing folder, and use the folder you just downloaded which should be named sows-2025-master to initialize it. Now, using the navigation menu on the bottom right, you should be able to head to the folder we just downloaded! You should see it contains a set of files including a folder named data.\n\n‚ö†Ô∏è To make sure that everything is working properly, run the following command in your console getwd() and make sure that the output path that is returned ends with sows-2025-master!"
  },
  {
    "objectID": "pages/1-setup.html#installing-packages",
    "href": "pages/1-setup.html#installing-packages",
    "title": "Setup",
    "section": "Installing packages",
    "text": "Installing packages\nThe analyses that we are going to conduct require specific packages. In R, packages are collections of functions which help us perform standardized workflows. In the code chunk below, we instruct R to install the packages that we will need later on throughout the workshop.\n\nüí° Copy and paste this and the other code chunks from here to your R script to follow.\n\n\n# Install required packages for subsequent analyses\nsource(\"./utils/installations.R\")\n\nDuring the installation, you will see many messages being displayed on your R console, don‚Äôt pay too much attention to them unless they are red and specify an error!\nIf you encounter any of these messages during installation, follow this procedure here:\n\n# R asks for package updates, answer \"n\" and type enter\n# Question displayed:\nUpdate all/some/none? [a/s/n]:\n\n# Answer to type:  \nn\n\n# R asks for installation from binary source, answer \"no\" and type enter\n# Question displayed:\nDo you want to install from sources the packages which need compilation? (Yes/no/cancel)\n\n# Answer to type:\nno"
  },
  {
    "objectID": "pages/2-spatial-data.html",
    "href": "pages/2-spatial-data.html",
    "title": "Spatial Data",
    "section": "",
    "text": "Get an introduction to the type of data we are going to use\nLoad the data into a Seurat object"
  },
  {
    "objectID": "pages/2-spatial-data.html#what-data-are-we-going-to-use-what-is-our-question",
    "href": "pages/2-spatial-data.html#what-data-are-we-going-to-use-what-is-our-question",
    "title": "Spatial Data",
    "section": "What data are we going to use? What is our question?",
    "text": "What data are we going to use? What is our question?\nAs seen during the presentation, we will load data originally collected in this study on High Grade Serous Ovarian Carcinoma (HGSOC). The original data supporting the findings of the study has been deposited on the Gene Expression Omnibus (GEO) data portal under accession number GSE211956.\nThe data (like all data from Visium experiments) is built in the following way and stored in the data folder:\n\nbarcodes.tsv: the single-cell barcodes from the 10X GEMs\nfeatures.tsv: the set of genes profiled during the experiment (in the case of RNA-seq)\nmatrix.mtx: the actual cell-by-gene matrix with the count information"
  },
  {
    "objectID": "pages/2-spatial-data.html#loading-the-data-with-seurat",
    "href": "pages/2-spatial-data.html#loading-the-data-with-seurat",
    "title": "Spatial Data",
    "section": "Loading The Data with Seurat",
    "text": "Loading The Data with Seurat\nOnce we know what to expect from the data, let‚Äôs load it! We are going to use functions from the Seurat package to load our tabular and image data into R so we can start working with it.\n\n# Load the data using Seurat (first set the proper data directory path)\ndatadir <- './data'\n\ncount_matrix <- Read10X(datadir,\n              gene.column = 2,\n              cell.column = 1,\n              unique.features = TRUE,\n              strip.suffix = FALSE)\n\n# Turn matrix into SeuratObject\nsp <- CreateSeuratObject(counts = count_matrix,\n                        project = 'visium-hgsoc',\n                        assay='Visium10X')              \n\n\nü§î How many spots and genes are present in our counts table? hint: think of the type of experiment and the readout we are expecting!\n\nLet‚Äôs take a look at the counts matrix up close:\n\n# Lets examine a few genes in the first thirty cells\nsp[['Visium10X']]$counts[c(\"CD3D\", \"TCL1A\", \"MS4A1\"), 1:30]\n\n3 x 30 sparse Matrix of class \"dgCMatrix\"\n\n\n                                                                 \nCD3D  1 . . . . . . . . 1 . . . . 2 . . . . . . 1 . . 1 . . . . .\nTCL1A . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\nMS4A1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\n\nThe . values in the matrix represent 0s (no molecules detected). Since most values in an scRNA-seq matrix are 0, Seurat uses a sparse-matrix representation whenever possible. This results in significant memory and speed savings for Drop-seq/inDrop/10X data.\nNow that we have created it, our sp object acts as a container for all the information we need during the analysis, more specifically, the SeuratObject class is composed in the following way:\n\n\n\nWe can see its structure also by printing it directly on screen:\n\n# Lets see what the object looks like\nsp\n\nAn object of class Seurat \n33538 features across 1504 samples within 1 assay \nActive assay: Visium10X (33538 features, 0 variable features)\n 1 layer present: counts\n\n\nWe can also access our transcript information in the object by using the [[ operator.\n\n# Lets see what the object looks like (we use the assay name given previously)\nsp[['Visium10X']]\n\nAssay (v5) data with 33538 features for 1504 cells\nFirst 10 features:\n MIR1302-2HG, FAM138A, OR4F5, AL627309.1, AL627309.3, AL627309.2,\nAL627309.4, AL732372.1, OR4F29, AC114498.1 \nLayers:\n counts \n\n\nNow go ahead and check the cell metadata!\n\n\nCode\nhead(sp@meta.data, 5)\n\n\n                     orig.ident nCount_Visium10X nFeature_Visium10X\nAAACAAGTATCTCCCA-1 visium-hgsoc             5383               2626\nAAACCGGGTAGGTACC-1 visium-hgsoc             9884               3677\nAAACCGTTCGTCCAGG-1 visium-hgsoc             9971               3687\nAAACCTCATGAAGTTG-1 visium-hgsoc            10324               3565\nAAACGAGACGGTTGAT-1 visium-hgsoc             7975               3227\n\n\n\nüí° See how Seurat has automatically created metadata fields related to number of genes and UMIs per spot?"
  },
  {
    "objectID": "pages/2-spatial-data.html#adding-image-data",
    "href": "pages/2-spatial-data.html#adding-image-data",
    "title": "Spatial Data",
    "section": "Adding image data",
    "text": "Adding image data\nMetadata refers to that class of accessory data to the main experimental readout. In the case of this published dataset, the main data refers to the actual gene expression table with the associated counts measurement for each sample. Each sample then has associated information used to further describe it (e.g.¬†type of cells, patient ID, treatment status, experimental batch‚Ä¶), as we have previously seen, this information is instrumental to bioinformaticians to avoid pitfalls in the analysis. In the case of our spatial data, we also have associated H&E images that we can use to overlay to actual mRNA information to aid interpretability of the results. Since we do not need it for any quantitative analysis, we are fine with loading a low-res image in .png format.\n\n# Let's load the image\nimg <- Read10X_Image(image.dir = \"./data/spatial/\"\n                     , image.name = \"tissue_lowres_image.png\"\n                     , assay = '10Xspatial'\n                     , slice = 'slice1'\n                     , filter.matrix = TRUE # This is used to retain only spots \"on tissue\"\n                     )\nimg\n\nSpatial coordinates for 1504 cells\nDefault segmentation boundary: centroids \nAssociated assay: 10Xspatial \nKey: slice1_ \n\n\nNow that we have loaded the image, we can put it inside our container object:\n\n# Assign image\nsp[['image']] <- img"
  },
  {
    "objectID": "pages/3-quality-control.html",
    "href": "pages/3-quality-control.html",
    "title": "Quality Control",
    "section": "",
    "text": "Data normalization and filtering\nNormalize and explore the data with functions provided by the Seurat and Giotto packages\nVisual exploration of QC metrics over the sample"
  },
  {
    "objectID": "pages/3-quality-control.html#overview",
    "href": "pages/3-quality-control.html#overview",
    "title": "Quality Control",
    "section": "Overview",
    "text": "Overview\nAs in all bioinformatics analyses, we need to make sure that the data we are analyzing is as sound as possible. Biological data is especially noisy and chaotic by its very nature, hence it is important to perform proper quality control (QC) steps and filtering.\n\nWhy filter?\nFiltering can help remove low-quality cells/spots that would otherwise introduce technical noise. For example, the presence of spots with lower numbers of features detected than other good quality spots can badly influence the clustering into groupings driven by total expression detected (UMIs) rather than by actual transcriptional content. Spots can also be considered low quality if they show signs of being poorly representative of the biological activity being studied. Some examples are cells that are actively dying (high mitochondrial gene expression) or observations that are actually doublets (in the case of single cell RNA-seq or imaging-based technologies). Removing these sources of non-relevant variation represents a key step for downstream analyses, improving the ratio of biological signal relative to technical noise.\n\n\nSpecial considerations with spatial data\nwhile filtering is beneficial in all usual single-cell analyses, spatial data requires an additional level of consideration. Removing a poor quality cell from a spatial network corresponds to removing a data point from its native environment.\n\nüö® If done without proper caution, this could damage our understanding of spatial niche makeup and cell-cell crosstalk!"
  },
  {
    "objectID": "pages/3-quality-control.html#qc-thresholds",
    "href": "pages/3-quality-control.html#qc-thresholds",
    "title": "Quality Control",
    "section": "QC Thresholds",
    "text": "QC Thresholds\nFiltering can be performed in many ways and using combinations of covariates to make sure we are retaining cells/spots we think are interesting for the sake of the analysis. Take note that this is a very analysis-based step! In our case, we are going to filter spots based on the amount of genes they encode and their total UMI content.\n\nüí° To get a feeling for what could be sensible thresholds to use for filtering, we have to get an idea of the average UMIs and genes!\n\nQ1. Go ahead and compute the average UMI value and gene values per spot, what are these values?"
  },
  {
    "objectID": "pages/3-quality-control.html#filtering",
    "href": "pages/3-quality-control.html#filtering",
    "title": "Quality Control",
    "section": "Filtering",
    "text": "Filtering\nOnce we have our filtering values sorted out, we need to actually filter our bad spots. Firstly though, since we are dealing with spatial data, we want to check whether the filtering we are applying could end up tampering with the original spatial organization of the sample!\nQ2. Determine a quantile-based approach to filter spots based on the nCount_Visium10X and nFeature_Visium10X columns, keeping only spots above the 10% percentile for both measures (let‚Äôs call them genesq for the number of genes and umisq for the number of counts, we‚Äôll use these later!) - hint: use the quantile function.\nQ3. Compute an additional meta.data column named to_keep which contains values Keep or Discard. If a spot passes QC then gets assigned a Keep else it is flagged by a Discard. (hint: check out the mutate and ifelse function to create the column)\nQ4. Plot the new column over the sample and check where spots that would be discarded are located\nQ5. How many spots would be filtered out?\n\n\n\n\n\n\n\n\n\nOnce we are done, we can actually filter the sample!\n\nsp <- subset(sp, subset = to_keep == 'Keep')\n\n\nüí° Did the filtering actually returned the expected amount of spots?"
  },
  {
    "objectID": "pages/3-quality-control.html#normalization",
    "href": "pages/3-quality-control.html#normalization",
    "title": "Quality Control",
    "section": "Normalization",
    "text": "Normalization\nAfter the removal of unwanted spots from the dataset, it‚Äôs time to normalize it. What this step tries to achieve is the removal of unwanted differences across spots given by their varying library sizes. More specifically, we use the NormalizeData function from Seurat that normalizes the feature expression measurements for each cell by the total expression, multiplies this by a scale factor (10,000 by default) and log-transforms the result. Normalized expression values are then stored in sp[[\"RNA\"]]$data.\n\nUse the NormalizeData function from Seurat to normalize the expression levels in our sample\n\n\nsp <- NormalizeData(sp, normalization.method = \"LogNormalize\", scale.factor = 10000)"
  },
  {
    "objectID": "pages/3-quality-control.html#selection-of-highly-variable-features",
    "href": "pages/3-quality-control.html#selection-of-highly-variable-features",
    "title": "Quality Control",
    "section": "Selection of Highly-variable features",
    "text": "Selection of Highly-variable features\nNow that we have our filtered dataset, we are ready to start working on the spots at the transcriptional level. First, we want to subset our counts matrix to retain information coming from genes which show interesting patterns in the data, in other words we want to keep genes which vary across our spots, since those should be the interesting ones!\nTo do so, try to implement the following steps in your code:\nQ6. Use the FindVariableFeatures function from the Seurat package to detect highly-variable genes in the data and keep the top 4,000 genes using the vst method\nQ7. Check which are the top 10 most variable genes in the data (hint: try a combination of the head and VariableFeatures function)\nQ8. Plot the names of the top 50 highly-variable genes like shown below (hint: use the VariableFeaturePlot function)\n\n# Top 10 most highly variable genes?\ntop10 <- NULL\n\n\n\n\n\n\n\n\n\n\n\nüí° Selecting HVGs is really only a trick to enhance the signal coming from the inner variability of the data, we are not discarding any information as all genes are available to us all the time anyways!"
  },
  {
    "objectID": "pages/3-quality-control.html#clustering-spatially-unaware",
    "href": "pages/3-quality-control.html#clustering-spatially-unaware",
    "title": "Quality Control",
    "section": "Clustering (spatially-unaware)",
    "text": "Clustering (spatially-unaware)\nClustering allows us to group spots together based on transcriptional similarity! In order to achieve this, we have to first perform a set of steps beforehand to prepare the data for the clustering algorithm we will use.\nFirst, we apply a linear transformation (‚Äòscaling‚Äô) that is a standard pre-processing step prior to dimensionality reduction techniques like PCA. The ScaleData() function:\n\nShifts the expression of each gene, so that the mean expression across cells is 0\nScales the expression of each gene, so that the variance across cells is 1\n\nThis step gives equal weight in downstream analyses, so that highly-expressed genes do not dominate\n\nThe results of this are stored in pbmc[[‚ÄúRNA‚Äù]]$scale.data\nBy default, only variable features are scaled.\n\nFollow along and perform these steps in your code:\nLet‚Äôs scale the data\n\nsp <- ScaleData(sp)\n\nWe then perform linear dimensionality reduction with PCA. In this case we want to isolate the axes of variation in the data, for each cell we will have new ‚Äúmetafeatures‚Äù in the form of Principal Components (PCs) which are linear combinations (think of it as a summary) of the contribution of the original genes of that cell!\n\n# Perform PCA on HVGs\nsp <- RunPCA(sp, features = VariableFeatures(object = sp))\n\nQ9. How many PCs are computed by default?\nQ10. Which are the top 10 genes contributing to the first 3 PCs (based on their loadings, hint: use the VizDimLoadings function)?\nGreat! We can now plot our spots in PCA space:\n\n# Plot PC1 vs PC2\nDimPlot(sp, reduction = \"pca\") + NoLegend()\n\n\n\n\n\n\n\n\nQ11. Now plot the PC score of each spot directly on the tissue in space (hint: this is stored in the sp@reductions$pca slot), to see whether there is a correlation between principal component and tissue location (like shown below), what do you expect?\n\n\n\n\n\n\n\n\n\n\nüí° If you are interested in exploring the relationship between cells, PCs and genes, try out the DimHeatmap function!"
  },
  {
    "objectID": "pages/3-quality-control.html#which-will-be-the-dimensionality-of-our-data",
    "href": "pages/3-quality-control.html#which-will-be-the-dimensionality-of-our-data",
    "title": "Quality Control",
    "section": "Which will be the ‚Äúdimensionality‚Äù of our data?",
    "text": "Which will be the ‚Äúdimensionality‚Äù of our data?\nIn order to overcome the technical noise in the data and highlight sources of relevant biological variation, we evaluate the transcriptional similarity of cells based on their ‚Äúsummarized‚Äù gene expression, in other words based on their principal components! But how can we decide how many components we should retain (out of the default ones)? 10? 15? Maybe 20? ü§î\nIn order to choose we can generate what is known as an Elbow plot, a heuristic method by which we select the number of PCs based on the percentage of variance explained by each one. In other words we retain PCs which ‚Äúsummarize‚Äù better the variability within the data, discarding ones which instead relate more to subtle technical variation.\n\nElbowPlot(sp)\n\n\n\n\n\n\n\n\nQ12. Draw an elbow plot yourself (hint: use the convenient ElbowPlot function)\n\nHow many PCs will you choose based on the plot? Would it make sense to pick 10?"
  },
  {
    "objectID": "pages/3-quality-control.html#non-linear-representation-of-the-data-umapt-sne",
    "href": "pages/3-quality-control.html#non-linear-representation-of-the-data-umapt-sne",
    "title": "Quality Control",
    "section": "Non-linear representation of the data (UMAP/t-SNE)",
    "text": "Non-linear representation of the data (UMAP/t-SNE)\nLinear representation of the data are very useful to perform interpretable dimensionality reduction, nevertheless one might want to visually represent (and only that!) the data in a meaningful manner that preserves the transcriptional cell-cell similarity. Methods like UMAP (Uniform Manifold Approximation and Projection) aim to do exactly this, they group together trancriptionally similar cells in a 2D plane, though sacrificing the representation of the global data structure.\nThe first thing that we want to do is select the amount of PCs that we want to use to compute the transcriptional neighbors of each spot (i.e.¬†other spots which have a very similar PCs profile). You should have figured this out by looking at the elbow plot above!\n\nndims <- 10 # Put here your number of chosen PCs\n\nLet‚Äôs compute the neighbors and UMAP embedding!\n\nsp <- FindNeighbors(sp, dims = 1:ndims)\nsp <- RunUMAP(sp, dims = 1:ndims)\n\nQ13. Plot the UMAP displaying the QC information we computed before (nFeature_RNA, nCount_RNA and transcriptome.complexity) using the FeaturePlot function\n\n\n\n\n\n\n\n\n\n\nWhat do you think of the results? How does it compare to your expectation also based on your previous experience with UMAP applied to single-cell data? Where you expecting more or less heterogeneity and diversity?"
  },
  {
    "objectID": "pages/3-quality-control.html#grouping-spots-together-with-clustering",
    "href": "pages/3-quality-control.html#grouping-spots-together-with-clustering",
    "title": "Quality Control",
    "section": "Grouping spots together with clustering",
    "text": "Grouping spots together with clustering\nHere we will try to group spots together based on their transcriptional similarity using specific clustering algorithms! This procedure enables us to see whether we can unsupervisedly dissect the transcriptional differences within the data. In order to do so, we partition the underlying graph connecting similar spots to one another (which we built with the FindNeighbors function) into islands of spots that we term clusters.\n\nüí° Note that we are still not considering spatial information for this analysis! We are purely evaluating transcriptional similarity!\n\nOne of the main parameters to consider here is the clustering resolution, this determines the granularity of our final clustering. In other words, higher resolution often leads to smaller and finer clusters while lower resolution values return broader clusters. The definition of this parameter is dependent on a series of factors including the type of data, its source and biology (i.e.¬†a tumor vs.¬†a more homogeneous sample) and our knowledge of the sample we are analyzing. Usually clustering results are also interpretable based on heuristic metrics used to evaluate stability, the silhouette score being one of them.\nLet‚Äôs now find clusters of spots in our data!\n\nsp <- FindClusters(sp, resolution = 0.8)\n\nModularity Optimizer version 1.3.0 by Ludo Waltman and Nees Jan van Eck\n\nNumber of nodes: 1339\nNumber of edges: 42820\n\nRunning Louvain algorithm...\nMaximum modularity in 10 random starts: 0.8047\nNumber of communities: 9\nElapsed time: 0 seconds\n\n\nQ14. How many clusters do you get?\nQ15. How many spots do we have per cluster on average?\nQ16. Represent cluster identities on a UMAP and on a spatial plot, does this match your expectation? Do you see clusters also grouping spatially?\n\n\n\n\n\n\n\n\n\nThese are my cluster identities for the top 5 cells in the data:\n\n\nAAACAAGTATCTCCCA-1 AAACCGGGTAGGTACC-1 AAACCGTTCGTCCAGG-1 AAACCTCATGAAGTTG-1 \n                 5                  4                  2                  1 \nAAACGAGACGGTTGAT-1 \n                 0 \nLevels: 0 1 2 3 4 5 6 7 8"
  },
  {
    "objectID": "pages/3-quality-control.html#find-differentially-expressed-marker-genes",
    "href": "pages/3-quality-control.html#find-differentially-expressed-marker-genes",
    "title": "Quality Control",
    "section": "Find differentially expressed marker genes",
    "text": "Find differentially expressed marker genes\nOnce we have identified a grouping for our spots, we can move on to check which are the transcriptional differences across these groups. The goal of this procedure is to start to get a feeling for the biology behind the clusters we have identified. We can use the FindAllMarkers function to compute all marker genes for all spot clusters against all other spots at once. What this function does under the hood is to perform a statistical test (several are implemented in Seurat) for each gene and return the corresponding p_val and log2FC which describe the signficance and magnitude of the gene expression change in the categories we selected (i.e.¬†cluster 1 vs all others).\n\n# With `only.pos` we tell the software to only report genes with positive change in each cluster compared to all others\nmarkers <- FindAllMarkers(sp, only.pos = TRUE)\n\nQ17. Check out the top 5 markers for each cluster of spots, is there any marker you recognize?\nQ18. Plot the expression of one of the main markers across clusters like shown below (hint: use the VlnPlot function)\n\n\n\n\n\n\n\n\n\nQ19. Plot the expression of one of the main markers on a UMAP embedding like shown below\n\n\n\n\n\n\n\n\n\nQ20. Visualize the expression of the top 5 marker genes per cluster in a heatmap (hint: use the DoHeatmap function)\n\n\n\n\n\n\n\n\n\n\nü§î Based on the very technical nature of the technology, would it make sense to expect clear-cut marker genes for each cluster specifically related to cell types?"
  },
  {
    "objectID": "pages/3-quality-control.html#cell-type-enrichment-of-spots",
    "href": "pages/3-quality-control.html#cell-type-enrichment-of-spots",
    "title": "Quality Control",
    "section": "Cell type enrichment of spots",
    "text": "Cell type enrichment of spots\nAs previously discussed, Visium assays gene expression in single larger-than-cells spots, meaning that each observation we get will contain mixed transcriptomes coming from neighboring cells. This can complicate downstream analysis when trying to infer cell-cell relationships and phenotypes. For this reason, there exist approaches aimed at dissecting this spot heterogeneity by either deconvolving the transcriptional signal of spots into contributions of single cell types or by evaluating the enrichment of cell type marker genes in the transcriptional profile of each single spot. The former are based on ‚Äúpure‚Äù transcriptional profiles usually distilled from a matched sample profiled with scRNA-seq, where cell clusters can be obtained and signals averaged. The latter approach is less computationally expensive, does not require scRNA-seq, but is entirely knowledge-based and less precise.\nFor the sake of this workshop, we will perform the second approach in the form of the clustermole package. This package contains a collection of cell-type specific marker genes coming from various databases whose activity can be avaluated across spots. In the background, we are essentially running a GSEA analysis on each single spot (ssGSEA) across all the available marker genesets in the database.\n\n# First extract normalized counts from our seurat object\nDefaultAssay(sp) <- \"Visium10X\"\ncounts <- GetAssayData(object = sp, layer = 'data') %>% as.matrix()\n\n# Run `clustermole`\nenr <- clustermole_enrichment(counts, species = \"hs\", method = 'ssgsea')\n\n# Filter results, keep only representative celltypes of interest OR celltypes in the `organ` Ovary\nct_to_match = c('Macrophage','CD4+ T cell', 'CD8+ T cell', 'Mesenchymal cell', 'Epithelial cell', 'Endothelial cell', 'Fibroblast')\n\nenr_wide <- enr %>% filter(species == 'Human') %>% filter(organ == 'Ovary' | celltype %in% ct_to_match) %>% tidyr::pivot_wider(.,id_cols=c(\"cluster\"), names_from = 'celltype', values_from = 'score', values_fn = mean, values_fill = 0) %>% tibble::column_to_rownames(\"cluster\")\n\n# Create a new column in metadata with labels from the enrichment (each spot is labelled for its highest score)\nenr_wide$celltype <- names(enr_wide)[max.col(enr_wide)]\n\n# Add them to metadata\nsp@meta.data <- sp@meta.data %>% merge(enr_wide, by.y=0, by.x=0, all.x=TRUE) %>% tibble::column_to_rownames(\"Row.names\")\n\nLet‚Äôs now plot spatially the scores for specific gene signatures of interest like shown below!\n\n# Plot in space\np1 <- SpatialFeaturePlot(sp, features = c('Epithelial cell (Ovarian Cancer)'), pt.size=3)\np2 <- SpatialDimPlot(sp,group.by = 'celltype', pt.size=3) + scale_fill_brewer(palette = 'Paired')\n\np1 + p2\n\n\n\n\n\n\n\n\n\nDraw a barplot using ggplot2 highlighting the proportions of celltypes predicted across clusters in the sample\n\n\n\n\n\n\n\n\n\n\n\nBased on the results above, can we confidently highlight a ‚Äútumor‚Äù cluster and a ‚Äústromal‚Äù one?\n\nNow we can move to additional downstream analyses which will also take into account spatial coordinates of spots on the sample!"
  },
  {
    "objectID": "pages/4-downstream.html",
    "href": "pages/4-downstream.html",
    "title": "Downstream Analyses",
    "section": "",
    "text": "Identification of spatially-coordinated genes\nIdentification of spatial domains\nLigand-receptor inference analysis with CellChat"
  },
  {
    "objectID": "pages/4-downstream.html#overview",
    "href": "pages/4-downstream.html#overview",
    "title": "Downstream Analyses",
    "section": "Overview",
    "text": "Overview\nNow you will start to explore ways to use spatial information to gather conclusions from our sample. You might be thinking of questions like:\n\nAre there genes that display a specific pattern of expression?\nAre my clusters more or less spatially organized? Can we include spatial information while clustering spots?\nWhat about cell-cell interactions across spots? Are there ways to check them out in spatial data?\n\nYou‚Äôll see in this part that most of these questions are readily answered after a few steps given our properly built dataset!"
  },
  {
    "objectID": "pages/4-downstream.html#spatially-variable-genes-with-giotto",
    "href": "pages/4-downstream.html#spatially-variable-genes-with-giotto",
    "title": "Downstream Analyses",
    "section": "Spatially-variable genes with Giotto",
    "text": "Spatially-variable genes with Giotto\nAs we have seen during the introduction, geographical data analysis approaches have been around for decades in the fields of economics and ecology. Ever since spatial profiling technologies were developed, researchers have re-purposed these mathematical approaches to study biological phenomena! One of the first applications initially developed for smFISH data was to check whether genes/probes displayed a more or less spatially organized pattern in a statistically relevant manner. The Giotto package takes advantage of these methods to detect spatially-variable genes in ST data.\nBefore that tough, we need a few setup steps. We first convert our SeuratObject into one which is compatible with the functionalities of Giotto. This is performed with a convenience function as shown below:\n\ngobj <- seuratToGiottoV5(sp, spatial_assay = 'Visium10X')\n\n# Need to re-scale the data after transformation into giotto object\ngobj <- normalizeGiotto(gobj)\n\n\nüí° Just write gobj in your console to inspect the Giotto object, everything we had before should be there!\n\nThen, we need to represent connections between spots in a way that the computer can understand, this is performed via networks. Think of them as ways to store connection between cells. Use the code below to create a k-Nearest Neighbor graph where each spot will be connected to its k sorrounding neighbors.\n\n# create spatial network\ngobj <- createSpatialNetwork(gobject = gobj,\n                                method = \"kNN\", \n                                     k = 6,\n                                     maximum_distance_knn = 300,\n                                     name = \"spatial_network\")\n\nThere are many ways to create spatial networks and the k-NN algorithm is only one of them, others include radius-based approaches and the Delaunay triangulation. Once we have created the network, we inspect it trying to see whether connections between spots make sense biologically! (i.e.¬†we are not connecting far away spots unlikely to interact with wach other)\n\n# Plot spatial network\nspatPlot2D(gobject = gobj,  \n            show_network= TRUE,\n            network_color = \"blue\",\n            point_size = 1, \n            spatial_network_name = \"spatial_network\")\n\n\n\n\n\n\n\n\nWe can now go ahead and detect spatially-variable genes in the data. Giotto implements this functionality with a function called binSpect, which is based on gene expression binarization and k-means clustering. The method tries to identify genes which are either expressed or not in nearby cells connected in the network.\n\n# Spatially variable genes detection\nranktest <- binSpect(gobj, \n                     bin_method = \"rank\",\n                     calc_hub = TRUE,\n                     subset_feats = VariableFeatures(sp),\n                     hub_min_int = 5,\n                     spatial_network_name = \"spatial_network\")\n\nQ1. Inspect the resulting object, what are the top 3 most spatially variable genes?\nQ2. Plot them on the sample like shown below (hint: use the spatFeatPlot2D function)"
  },
  {
    "objectID": "pages/4-downstream.html#check-out-spatial-modules-of-expression",
    "href": "pages/4-downstream.html#check-out-spatial-modules-of-expression",
    "title": "Downstream Analyses",
    "section": "Check out spatial modules of expression",
    "text": "Check out spatial modules of expression\nAnother functionality of Giotto entails the discovery of modules of genes displaying coordinated and coherent expression patterns, these can be thought to encode a spatially coordinated biological function. As this is a computationally-intensive process, we restrict the search of modules to include the top 250 spatially-variable genes like shown below:\n\n# Cluster the top 500 spatially variable genes into modules\next_spatial_genes <- ranktest[1:250,]$feats\n\nWith the function below, we are computing which genes are more likely to compose modules by checking their cross-correlation profile.\n\n# Compute gene-gene spatial correlation\nspat_cor_netw_DT <- detectSpatialCorFeats(\n    gobj,\n    method = \"network\",\n    spatial_network_name = \"spatial_network\",\n    subset_feats = ext_spatial_genes)\n\nWe then cluster the features into 5 modules, this is an arbitrary choice and can be dependent on the nature of the analysis.\n\nspat_cor_netw_DT <- clusterSpatialCorFeats(spat_cor_netw_DT, \n                                           name = \"spat_netw_clus\", \n                                           k = 5)\n\nPlot the clusters!\n\nheatmSpatialCorFeats(gobj,\n                     spatCorObject = spat_cor_netw_DT,\n                     use_clus_name = \"spat_netw_clus\",\n                     heatmap_legend_param = list(title = NULL))\n\n\n\n\n\n\n\n\nWe can additionally summarize the activity of spatial modules into metascores at single spot level, this is equivalent to calculating a signature score at the single-spot level starting from th e lists of genes composing the modules. We expect to see a spatial patterning in the data. We can additionally plot a figure to check out how many genes there are per module and how much they are intercorrelated!\n\n# Rank clusters (also plots cluster size vs rank dotplot)\nnetw_ranks <- rankSpatialCorGroups(\n  gobj,\n  spatCorObject = spat_cor_netw_DT, \n  use_clus_name = \"spat_netw_clus\")\n\n\n\n\n\n\n\ncluster_genes_DT <- showSpatialCorFeats(spat_cor_netw_DT, \n                                        use_clus_name = \"spat_netw_clus\", \n                                        show_top_feats = 1)\n\n# Get gene-clusters associations\ncluster_genes <- cluster_genes_DT$clus \nnames(cluster_genes) <- cluster_genes_DT$feat_ID\n\n# Create metagenes based on modules\ngobj <- createMetafeats(gobj, \n                                feat_clusters = cluster_genes, \n                                name = \"cluster_metagene\")\n\n\nPlot metafeatures like shown below (hint: use the spatCellPlot function from the Giotto package but specify netw_ranks$clusters in the cell_annotation_value option)\n\n\n\n\n\n\n\n\n\n\nWe can also compute a set of the 30 top-expressed genes per module to then use to subset out sample and perform spatially-informed clustering!\n\n# Get a list of the top 30 co-expressed genes per cluster - hide this and have them work it out\ncoexpr_dt <- data.table::data.table(\n  genes = names(spat_cor_netw_DT$cor_clusters$spat_netw_clus),\n  cluster = spat_cor_netw_DT$cor_clusters$spat_netw_clus)\n\ndata.table::setorder(coexpr_dt, cluster)\n\ntop30_coexpr_dt <- coexpr_dt[, head(.SD, 30) , by = cluster]\n\nspatial_genes <- top30_coexpr_dt$genes\n\nQ3 Which are the top 3 genes for each spatial co-expression cluster?"
  },
  {
    "objectID": "pages/4-downstream.html#spatial-domain-identification-with-spatially-informed-clustering",
    "href": "pages/4-downstream.html#spatial-domain-identification-with-spatially-informed-clustering",
    "title": "Downstream Analyses",
    "section": "Spatial domain identification with spatially-informed clustering",
    "text": "Spatial domain identification with spatially-informed clustering\nNow that we have a set of genes that we know display spatial patterns of expression, we can use these to group together cells with clustering like we have previously done. In this case, the results that we obtain will intrinsically retain spatial information, meaning that we can identify spatially-guided results. We therefore start from the spatial genes to calculate again the principal components, umap, network and clustering!\n\n# Perform PCA on features from spatially-variable genes\nsp <- Seurat::RunPCA(sp,\n            features = spatial_genes,\n            reduction.name = \"custom_pca\",\n            )\n\n# Re-compute UMAP embedding\nsp <- Seurat::FindNeighbors(sp, reduction='custom_pca', graph.name='custom_NN')\n\n\n#sp <- Seurat::RunUMAP(sp, graph='custom_NN', reduction.name='custom_UMAP')\n\n# Cluster spots based on PCA neighbors from spatially-variable genes\nsp <- Seurat::FindClusters(sp, \n                            graph.name = \"custom_NN\",\n                            cluster.name = \"custom_clusters\")\n\nModularity Optimizer version 1.3.0 by Ludo Waltman and Nees Jan van Eck\n\nNumber of nodes: 1339\nNumber of edges: 12730\n\nRunning Louvain algorithm...\nMaximum modularity in 10 random starts: 0.7970\nNumber of communities: 9\nElapsed time: 0 seconds\n\n\nQ4. Display the resulting spatial domains you obtained (hint: try using the SpatialDimPlot function with the custom_leiden metadata field)\nQ5. Calculate the results of the previous clusters with the clustering obtained now, how much is each previous cluster contained in the new ones?\nQ6. Display cell type proportions across the identified domains using a heatmap (hint: see the pheatmap package)"
  },
  {
    "objectID": "pages/4-downstream.html#ligand-receptor-activity-inference-with-cellchat",
    "href": "pages/4-downstream.html#ligand-receptor-activity-inference-with-cellchat",
    "title": "Downstream Analyses",
    "section": "Ligand-receptor activity inference with CellChat",
    "text": "Ligand-receptor activity inference with CellChat\nEver since the widespread generation of scRNA-seq data, computational methods to infer cell-cell interaction events (CCI) have been developed based on co-expression of ligand- and receptor-encoding genes across clusters. Spatial techonologies deepen this analysis by giving us the chance to weight the inferred interaction by their actual spatial proximity, limiting the chance of identifying false positive results.\nThe method that we will exploit in this part of the workshop is packaged into the CellChat framework.\nWe first take the original SeuratObject and create a CellChat object with its own class. We first isolate raw data and import scale factors since CellChat takes into account spatial information, check out the steps below:\n\n# Get normalized data matrix\ndata.input = Seurat::GetAssayData(sp, slot = \"data\", assay = \"Visium10X\")\n\n# Source scale factors for um to px conversion\n# Of note, the 'spot_diameter_fullres' factor is different from the `spot` in Seurat object and thus users still need to get the value from the original json file. \nscalefactors = jsonlite::fromJSON(txt = file.path(\"./data/spatial\", 'scalefactors_json.json'))\n\n# manually create a dataframe consisting of the cell labels, make sure to avoid 0 in the labels, so we create another column\nmeta = data.frame(orig.labels = Idents(sp), samples = \"sample1\", row.names = names(Idents(sp))) %>% mutate(labels = paste0('cluster-',orig.labels))\nmeta$samples <- factor(meta$samples)\nunique(meta$labels) # check the cell labels\n\n[1] \"cluster-3\" \"cluster-1\" \"cluster-4\" \"cluster-5\" \"cluster-8\" \"cluster-0\"\n[7] \"cluster-6\" \"cluster-7\" \"cluster-2\"\n\nspatial.locs = GetTissueCoordinates(sp, scale = NULL, cols = c(\"imagerow\", \"imagecol\"))[,c('x','y')] %>% as.matrix()\n\nspot.size = 65 # the theoretical spot size (um) in 10X Visium\nconversion.factor = spot.size/scalefactors$spot_diameter_fullres\nspatial.factors = data.frame(ratio = conversion.factor, tol = spot.size/2)\n\nd.spatial <- computeCellDistance(coordinates = spatial.locs, ratio = spatial.factors$ratio, tol = spatial.factors$tol)\nmin(d.spatial[d.spatial!=0]) # this value should approximately equal 100um for 10X Visium data\n\n[1] 99.57156\n\n\nNow create the CellChat object and store it in the cellchat variable:\n\n# Create CellChat object\ncellchat <- createCellChat(object = data.input, meta = meta, group.by = \"labels\",\n                           datatype = \"spatial\", coordinates = spatial.locs, spatial.factors = spatial.factors)\n\n[1] \"Create a CellChat object from a data matrix\"\nCreate a CellChat object from spatial transcriptomics data... \nSet cell identities for the new CellChat object \nThe cell groups used for CellChat analysis are  cluster-0, cluster-1, cluster-2, cluster-3, cluster-4, cluster-5, cluster-6, cluster-7, cluster-8 \n\n# Let's see it\ncellchat\n\nAn object of class CellChat created from a single dataset \n 33538 genes.\n 1339 cells. \nCellChat analysis of spatial data! The input spatial locations are \n                   x_cent y_cent\nAAACAAGTATCTCCCA-1   6982   7857\nAAACCGGGTAGGTACC-1   6061   3067\nAAACCGTTCGTCCAGG-1   7192   3969\nAAACCTCATGAAGTTG-1   5496   2486\nAAACGAGACGGTTGAT-1   5286   6373\nAAACTGCTGGCTCCAA-1   6410   5592\n\n\nBuild a ligand-receptor database:\n\nCellChatDB <- CellChatDB.human # use CellChatDB.human since running on human data\n\nTake a look at it:\n\ndplyr::glimpse(CellChatDB$interaction)\n\nRows: 3,233\nColumns: 28\n$ interaction_name         <chr> \"TGFB1_TGFBR1_TGFBR2\", \"TGFB2_TGFBR1_TGFBR2\",‚Ä¶\n$ pathway_name             <chr> \"TGFb\", \"TGFb\", \"TGFb\", \"TGFb\", \"TGFb\", \"TGFb‚Ä¶\n$ ligand                   <chr> \"TGFB1\", \"TGFB2\", \"TGFB3\", \"TGFB1\", \"TGFB1\", ‚Ä¶\n$ receptor                 <chr> \"TGFbR1_R2\", \"TGFbR1_R2\", \"TGFbR1_R2\", \"ACVR1‚Ä¶\n$ agonist                  <chr> \"TGFb agonist\", \"TGFb agonist\", \"TGFb agonist‚Ä¶\n$ antagonist               <chr> \"TGFb antagonist\", \"TGFb antagonist\", \"TGFb a‚Ä¶\n$ co_A_receptor            <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"‚Ä¶\n$ co_I_receptor            <chr> \"TGFb inhibition receptor\", \"TGFb inhibition ‚Ä¶\n$ annotation               <chr> \"Secreted Signaling\", \"Secreted Signaling\", \"‚Ä¶\n$ interaction_name_2       <chr> \"TGFB1 - (TGFBR1+TGFBR2)\", \"TGFB2 - (TGFBR1+T‚Ä¶\n$ evidence                 <chr> \"KEGG: hsa04350\", \"KEGG: hsa04350\", \"KEGG: hs‚Ä¶\n$ is_neurotransmitter      <chr> \"FALSE\", \"FALSE\", \"FALSE\", \"FALSE\", \"FALSE\", ‚Ä¶\n$ ligand.symbol            <chr> \"TGFB1\", \"TGFB2\", \"TGFB3\", \"TGFB1\", \"TGFB1\", ‚Ä¶\n$ ligand.family            <chr> \"TGF-beta\", \"TGF-beta\", \"TGF-beta\", \"TGF-beta‚Ä¶\n$ ligand.location          <chr> \"Extracellular matrix, Secreted, Extracellula‚Ä¶\n$ ligand.keyword           <chr> \"Disease variant, Signal, Reference proteome,‚Ä¶\n$ ligand.secreted_type     <chr> \"growth factor\", \"growth factor\", \"cytokine;g‚Ä¶\n$ ligand.transmembrane     <chr> \"FALSE\", \"FALSE\", \"TRUE\", \"FALSE\", \"FALSE\", \"‚Ä¶\n$ receptor.symbol          <chr> \"TGFBR2, TGFBR1\", \"TGFBR2, TGFBR1\", \"TGFBR2, ‚Ä¶\n$ receptor.family          <chr> \"Protein kinase superfamily, TKL Ser/Thr prot‚Ä¶\n$ receptor.location        <chr> \"Cell membrane, Secreted, Membrane raft, Cell‚Ä¶\n$ receptor.keyword         <chr> \"Membrane, Secreted, Disulfide bond, Kinase, ‚Ä¶\n$ receptor.surfaceome_main <chr> \"Receptors\", \"Receptors\", \"Receptors\", \"Recep‚Ä¶\n$ receptor.surfaceome_sub  <chr> \"Act.TGFB;Kinase\", \"Act.TGFB;Kinase\", \"Act.TG‚Ä¶\n$ receptor.adhesome        <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"‚Ä¶\n$ receptor.secreted_type   <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"‚Ä¶\n$ receptor.transmembrane   <chr> \"TRUE\", \"TRUE\", \"TRUE\", \"TRUE\", \"TRUE\", \"TRUE‚Ä¶\n$ version                  <chr> \"CellChatDB v1\", \"CellChatDB v1\", \"CellChatDB‚Ä¶\n\n\n\nHow many ligand-receptor pairs in the database refer to secretory signalling pathways? (hint: use the showDatabaseCategory function from CellChat)\n\nWe can now move into the actual CellChat main workflow steps:\n\n# Filter database of interactions to keep Secreted Signaling only\nCellChatDB.use <- subsetDB(CellChatDB, search = \"Secreted Signaling\", key = \"annotation\") \n\n# Insert the filtered database into the cellchat object\ncellchat@DB <- CellChatDB.use\n\n# This step is necessary even if using the whole database, let's keep the highly variable genes in the data for speed\ncellchat <- subsetData(cellchat, features = VariableFeatures(sp))\n\n# With these functions it starts computing interaction scores in each spot\ncellchat <- identifyOverExpressedGenes(cellchat)\ncellchat <- identifyOverExpressedInteractions(cellchat, variable.both = F)\n\nThe number of highly variable ligand-receptor pairs used for signaling inference is 46 \n\n\nNow we can compute interaction probabilities across clusters based on spatial proximity:\n\n# Compute communication probabilities across the originally identified cluster\ncellchat <- computeCommunProb(cellchat, type = \"truncatedMean\", trim = 0.1,\n                              distance.use = TRUE, interaction.range = 250, scale.distance = 0.01,\n                              contact.dependent = TRUE, contact.range = 100, nboot=10)\n\ntruncatedMean is used for calculating the average gene expression per cell group. \n[1] \">>> Run CellChat on spatial transcriptomics data using distances as constraints of the computed communication probability <<< [2025-09-09 00:46:22.625019]\"\nMolecules of the input L-R pairs are diffusible. Run CellChat in a diffusion manner based on the `interaction.range`.\n[1] \">>> CellChat inference is done. Parameter values are stored in `object@options$parameter` <<< [2025-09-09 00:47:29.758543]\"\n\n# Aggregate results\ncellchat <- aggregateNet(cellchat)\n\n\nVisualize the number of interactions detected and their strenght using chord diagrams like shown below (hint: use the netVisual_circle function)\n\n\npar(mfrow = c(1,2), xpd=TRUE)\n# Number of interactions\nnetVisual_circle(cellchat@net$count, vertex.weight = rowSums(cellchat@net$count), weight.scale = T, label.edge= F, title.name = \"Number of interactions\")\n\n# Interaction strength\nnetVisual_circle(cellchat@net$weight, vertex.weight = rowSums(cellchat@net$weight), weight.scale = T, label.edge= F, title.name = \"Interaction weights/strength\")\n\n\n\n\n\n\n\n\n\nVisualize pairwise interactions using a heatmap (hint: use the netVisual_heatmap function)\n\n\nnetVisual_heatmap(cellchat, measure = \"count\", color.heatmap = \"Blues\")\n\n\n\n\n\n\n\n\nQ7. Which are the clusters with the highest level of interactions? (hint: check out the cellchatnet$count object)\nQ8. Which are the top 3 interactions across cluster-3 (Tumor) and cluster-2 (Stroma/Fibroblasts)? (hint: use the subsetCommunication function from CellChat)\nLet‚Äôs compute the overall activity of CCI at the pathway level, in this case the goal is to summarize the interactions that we have retrieved to ones that pertain to specific intracellular pathways in order to get a sense of what is going on in communicating cells!\n\ncellchat <- computeCommunProbPathway(cellchat)\n\nLet‚Äôs now see the activity of a specific pathway always using a chord diagram:\n\npathways.show <- c(\"FGF\") \n# Circle plot\npar(mfrow=c(1,1), xpd = TRUE) \nnetVisual_aggregate(cellchat, signaling = pathways.show, layout = \"circle\")\n\n\n\n\n\n\n\n\nQ9. Plot this in space as well like shown below (hint: use the netVisual_aggregate function)\n\n\n\n\n\n\n\n\n\nWe can additionally plot a ‚Äúbinarized‚Äù sender/receiver version of the plot above for a specific pathway:\n\n# Take an input of a ligand-receptor pair and show expression in binary\np1 <- spatialFeaturePlot(cellchat, pairLR.use = \"FGF18_FGFR4\", point.size = 1, do.binary = TRUE, cutoff = 0.05, enriched.only = F, color.heatmap = \"Reds\", direction = 1)\np2 <- spatialFeaturePlot(cellchat, pairLR.use = \"CXCL9_ACKR1\", point.size = 1, do.binary = TRUE, cutoff = 0.05, enriched.only = F, color.heatmap = \"Reds\", direction = 1)\n\np1 + p2\n\n\n\n\n\n\n\n\nCongratulations! You made it all the way to the end of the workshop! ü•≥"
  },
  {
    "objectID": "pages/index.html",
    "href": "pages/index.html",
    "title": "Introduction",
    "section": "",
    "text": "The brief workshop will give an overview on how to tackle the analysis of spatial molecular data. During the workshop we will dive into a spatial transcriptomics experiment and carry out the main steps of a standard data analysis pipeline."
  },
  {
    "objectID": "pages/index.html#introduction",
    "href": "pages/index.html#introduction",
    "title": "Introduction",
    "section": "Introduction",
    "text": "Introduction\n\nSetup RStudio\nGet familiar with the interface\nDownload relevant packages and set up the computing environment\nGet an introduction to the type of data we are going to use"
  },
  {
    "objectID": "pages/index.html#overview-of-the-data-and-qc",
    "href": "pages/index.html#overview-of-the-data-and-qc",
    "title": "Introduction",
    "section": "Overview of the data and QC",
    "text": "Overview of the data and QC\n\nLearn about data normalization and filtering\nNormalize and explore the data with functions provided by the Seurat and Giotto packages\nDimensionality reduction\nClustering\nCell type profile decomposition and spot enrichment with clustermole"
  },
  {
    "objectID": "pages/index.html#downstream-analyses-leveraging-spatial-information",
    "href": "pages/index.html#downstream-analyses-leveraging-spatial-information",
    "title": "Introduction",
    "section": "Downstream analyses leveraging spatial information",
    "text": "Downstream analyses leveraging spatial information\n\nIdentification of spatially-coordinated genes\nIdentification of spatially-aware spot domains\nLigand-receptor inference analysis with CellChat"
  },
  {
    "objectID": "pages/index.html#how-to-reach-us",
    "href": "pages/index.html#how-to-reach-us",
    "title": "Introduction",
    "section": "How To Reach Us",
    "text": "How To Reach Us\n\nLorenzo Drufuca (lorenzo.drufuca@ifom.eu)\nAnna Grattagliano (anna.grattagliano@ifom.eu)\nMattia Toninelli (mattia.toninelli@ifom.eu)\n\n\n\n\nFeel free to drop us an e-mail if you have any curiosity or question!"
  }
]